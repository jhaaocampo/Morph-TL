{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b470f8f-5fd7-4323-8ca2-a1535c83befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.txt\", \"r\", encoding=\"utf-8\") as f: \n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines = [line.strip() for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fde7b4a-e1cf-4348-9539-4d1e5c780c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MANILA - Isang task force ang binuo ng ng National Capital Region Police Office (NCRPO) nitong Lunes upang tugisin ang suspek sa pagpatay ng dalawang opisyal ng Commission on Elections (Comelec). Ang suspek ay napabalitang nakatakas kamakailan mula sa piitan ng isang kampo ng pulisya.',\n",
       " 'Ayon kay Chief Superintendent Eric Javier, NCRPO officer-in-charge, nilikha ang Task Force Ampatuan upang hanapin si PO2 Basser Ampatuan. Ngunit pinabulaanan ni Javier na nakatakas ang suspek, dahil di naman daw ito nake-ditene.',\n",
       " 'Si Chief Inspector Agapito Quimson, ang namumuno sa task force, ayon kay Javier.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_lines = []\n",
    "\n",
    "for line in lines:\n",
    "    if not line.strip():\n",
    "        continue  # remove empty lines\n",
    "    if line.startswith(\"=\") and line.endswith(\"=\"):\n",
    "        continue  # remove titles\n",
    "    clean_lines.append(line)\n",
    "\n",
    "clean_lines[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e9ad1b-9cdc-4d65-8df9-4585201e4178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered words: 227175\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "\n",
    "# Set to store unique words\n",
    "all_words_set = set()\n",
    "\n",
    "# Regex to match Tagalog-character words (letters + hyphen)\n",
    "word_pattern = re.compile(r\"[a-zA-ZñÑáéíóúÁÉÍÓÚ\\-]+\")\n",
    "\n",
    "for line in clean_lines:\n",
    "    # Normalize Unicode to NFC\n",
    "    line = unicodedata.normalize(\"NFC\", line)\n",
    "    \n",
    "    # Standardize whitespace\n",
    "    line = re.sub(r\"\\s+\", \" \", line).strip()\n",
    "    \n",
    "    # Separate punctuation from words\n",
    "    line = re.sub(r\"([.,!?;:()\\\"“”‘’])\", r\" \\1 \", line)\n",
    "    \n",
    "    # Find all candidate words\n",
    "    words = word_pattern.findall(line)\n",
    "    \n",
    "    for word in words:\n",
    "        word_clean = word.strip()\n",
    "    \n",
    "        # Skip words with any uppercase (proper nouns, acronyms, etc.)\n",
    "        if any(c.isupper() for c in word_clean):\n",
    "            continue\n",
    "        \n",
    "        # Skip short or very long words\n",
    "        if not (3 <= len(word_clean) <= 25):\n",
    "            continue\n",
    "        \n",
    "        all_words_set.add(word_clean)\n",
    "\n",
    "# sorted() ensures deterministic order every run (sets are unordered)\n",
    "all_words = sorted(all_words_set)\n",
    "print(f\"Number of filtered words: {len(all_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06b2172c-99eb-41a3-960c-a018ca6ae3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# all_words is sorted for deterministic input; seed fixes the random selection\n",
    "random.seed(42)\n",
    "\n",
    "if len(all_words) > 10000:\n",
    "    candidates_10k = random.sample(all_words, 10000)\n",
    "else:\n",
    "    candidates_10k = all_words\n",
    "\n",
    "len(candidates_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87cec19a-88a2-428e-806e-cb35e7ddc0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Morpheme Coverage Pre-check (on 10k pool) ──\n",
      "Type            Candidates   Target     Ratio    Status\n",
      "----------------------------------------------------------\n",
      "Prefix          4436         1260       3.5      OK\n",
      "Suffix          2077         980        2.1      OK\n",
      "Infix           1229         595        2.1      OK\n",
      "Circumfix       264          560        0.5      LOW — expand source text\n",
      "Reduplication   23           105        0.2      LOW — expand source text\n",
      "\n",
      "Note: counts overlap (a word can be both prefix + suffix candidate).\n",
      "This is a rough headroom check only — manual sorting is your quality gate.\n"
     ]
    }
   ],
   "source": [
    "# ── MORPHEME COVERAGE PRE-CHECK (run on candidates_10k before CSV export) ──\n",
    "import re\n",
    "\n",
    "prefixes    = ['mag', 'nag', 'pag', 'mang', 'nang', 'sang', 'tag', 'ma', 'na', 'ka', 'pa', 'i']\n",
    "suffixes    = ['in', 'an', 'han', 'hin', 'ng']\n",
    "infixes     = ['um', 'in']\n",
    "circumfixes = [('pag', 'in'), ('pag', 'an'), ('ka', 'an'), ('ma', 'an')]\n",
    "reduplication_pattern = re.compile(r'^(\\w{2,})-\\1$')\n",
    "\n",
    "prefix_candidates, suffix_candidates = [], []\n",
    "infix_candidates, circumfix_candidates, reduplication_candidates = [], [], []\n",
    "\n",
    "for word in candidates_10k:\n",
    "    if reduplication_pattern.match(word):\n",
    "        reduplication_candidates.append(word)\n",
    "        continue\n",
    "\n",
    "    is_circumfix = False\n",
    "    for (pre, suf) in circumfixes:\n",
    "        if word.startswith(pre) and word.endswith(suf) and len(word) > len(pre) + len(suf):\n",
    "            circumfix_candidates.append(word)\n",
    "            is_circumfix = True\n",
    "            break\n",
    "    if is_circumfix:\n",
    "        continue\n",
    "\n",
    "    if any(word.startswith(p) for p in prefixes):\n",
    "        prefix_candidates.append(word)\n",
    "    if any(word.endswith(s) for s in suffixes):\n",
    "        suffix_candidates.append(word)\n",
    "    for inf in infixes:\n",
    "        idx = word.find(inf)\n",
    "        if 0 < idx <= 3:\n",
    "            infix_candidates.append(word)\n",
    "            break\n",
    "\n",
    "targets = {'Prefix': 1260, 'Suffix': 980, 'Infix': 595, 'Circumfix': 560, 'Reduplication': 105}\n",
    "counts  = {\n",
    "    'Prefix': len(prefix_candidates), 'Suffix': len(suffix_candidates),\n",
    "    'Infix': len(infix_candidates), 'Circumfix': len(circumfix_candidates),\n",
    "    'Reduplication': len(reduplication_candidates),\n",
    "}\n",
    "\n",
    "print('── Morpheme Coverage Pre-check (on 10k pool) ──')\n",
    "print(f'{\"Type\":<15} {\"Candidates\":<12} {\"Target\":<10} {\"Ratio\":<8} Status')\n",
    "print('-' * 58)\n",
    "for morpheme, target in targets.items():\n",
    "    count = counts[morpheme]\n",
    "    ratio = count / target\n",
    "    status = 'OK' if ratio >= 1.9 else 'LOW — expand source text'\n",
    "    print(f'{morpheme:<15} {count:<12} {target:<10} {ratio:<8.1f} {status}')\n",
    "\n",
    "print('\\nNote: counts overlap (a word can be both prefix + suffix candidate).')\n",
    "print('This is a rough headroom check only — manual sorting is your quality gate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0135f39a-c766-40da-aad6-67f903140e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guaranteed morpheme words (deduped): 4416\n",
      "Final pool size: 10000\n"
     ]
    }
   ],
   "source": [
    "# ── TOP-UP: Build new pool from scratch to guarantee morpheme coverage ──\n",
    "# Single seed at the top — all_words is sorted so shuffles are fully deterministic\n",
    "random.seed(42)\n",
    "\n",
    "# Helper functions\n",
    "def is_suffix(w): return any(w.endswith(s) for s in suffixes)\n",
    "def is_infix(w):  return any(0 < w.find(inf) <= 3 for inf in infixes)\n",
    "def is_circ(w):   return any(w.startswith(p) and w.endswith(s) and len(w) > len(p)+len(s) for p,s in circumfixes)\n",
    "def is_redup(w):  return bool(reduplication_pattern.match(w))\n",
    "\n",
    "# Step 1: Collect all candidates per type from sorted all_words\n",
    "pool_suffix = [w for w in all_words if is_suffix(w)]\n",
    "pool_infix  = [w for w in all_words if is_infix(w)]\n",
    "pool_circ   = [w for w in all_words if is_circ(w)]\n",
    "pool_redup  = [w for w in all_words if is_redup(w)]\n",
    "\n",
    "# Step 2: Shuffle each pool (deterministic because all_words is sorted + seed is set)\n",
    "random.shuffle(pool_suffix)\n",
    "random.shuffle(pool_infix)\n",
    "random.shuffle(pool_circ)\n",
    "random.shuffle(pool_redup)\n",
    "\n",
    "# Step 3: Take 2x target from each type, deduplicate\n",
    "guaranteed = list(dict.fromkeys(\n",
    "    pool_suffix[:(980*2)] +\n",
    "    pool_infix[:(595*2)] +\n",
    "    pool_circ[:(560*2)] +\n",
    "    pool_redup[:(105*2)]\n",
    "))\n",
    "print(f\"Guaranteed morpheme words (deduped): {len(guaranteed)}\")\n",
    "\n",
    "# Step 4: Fill remaining slots from all_words excluding guaranteed\n",
    "guaranteed_set = set(guaranteed)\n",
    "remaining_pool = [w for w in all_words if w not in guaranteed_set]\n",
    "random.shuffle(remaining_pool)\n",
    "\n",
    "slots_left = 10000 - len(guaranteed)\n",
    "filler = remaining_pool[:slots_left]\n",
    "\n",
    "# Step 5: Combine and shuffle\n",
    "candidates_10k = guaranteed + filler\n",
    "random.shuffle(candidates_10k)\n",
    "\n",
    "print(f\"Final pool size: {len(candidates_10k)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04de5d0-8328-4b75-9a21-04cb9eaf9bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Re-check after top-up ──\n",
      "Type            Candidates   Target     Ratio    Status\n",
      "----------------------------------------------------------\n",
      "Prefix          3473         1260       2.8      OK\n",
      "Suffix          3256         980        3.3      OK\n",
      "Infix           2181         595        3.7      OK\n",
      "Circumfix       1447         560        2.6      OK\n",
      "Reduplication   234          105        2.2      OK\n",
      "\n",
      "Final pool size: 10000\n"
     ]
    }
   ],
   "source": [
    "# ── RE-CHECK after top-up ──\n",
    "prefix_candidates, suffix_candidates = [], []\n",
    "infix_candidates, circumfix_candidates, reduplication_candidates = [], [], []\n",
    "\n",
    "for word in candidates_10k:\n",
    "    if reduplication_pattern.match(word):\n",
    "        reduplication_candidates.append(word)\n",
    "        continue\n",
    "\n",
    "    is_circumfix = False\n",
    "    for (pre, suf) in circumfixes:\n",
    "        if word.startswith(pre) and word.endswith(suf) and len(word) > len(pre) + len(suf):\n",
    "            circumfix_candidates.append(word)\n",
    "            is_circumfix = True\n",
    "            break\n",
    "    if is_circumfix:\n",
    "        continue\n",
    "\n",
    "    if any(word.startswith(p) for p in prefixes):\n",
    "        prefix_candidates.append(word)\n",
    "    if any(word.endswith(s) for s in suffixes):\n",
    "        suffix_candidates.append(word)\n",
    "    for inf in infixes:\n",
    "        idx = word.find(inf)\n",
    "        if 0 < idx <= 3:\n",
    "            infix_candidates.append(word)\n",
    "            break\n",
    "\n",
    "counts = {\n",
    "    'Prefix': len(prefix_candidates), 'Suffix': len(suffix_candidates),\n",
    "    'Infix': len(infix_candidates), 'Circumfix': len(circumfix_candidates),\n",
    "    'Reduplication': len(reduplication_candidates),\n",
    "}\n",
    "\n",
    "print('── Re-check after top-up ──')\n",
    "print(f'{\"Type\":<15} {\"Candidates\":<12} {\"Target\":<10} {\"Ratio\":<8} Status')\n",
    "print('-' * 58)\n",
    "for morpheme, target in targets.items():\n",
    "    count = counts[morpheme]\n",
    "    ratio = count / target\n",
    "    status = 'OK' if ratio >= 1.9 else 'LOW — still need more'\n",
    "    print(f'{morpheme:<15} {count:<12} {target:<10} {ratio:<8.1f} {status}')\n",
    "\n",
    "print(f'\\nFinal pool size: {len(candidates_10k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3401761-ae02-42a9-8902-87d2aa64295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert list to DataFrame (one word per row)\n",
    "df = pd.DataFrame(candidates_10k, columns=[\"word\"])\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv(\"candidates_10k.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2992b563-b981-4ab1-91cc-51c4d49b80d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
